{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c8b3ac",
   "metadata": {},
   "source": [
    "### En este script se incluyen las fases descriptiva y predictiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generar_datos_cuantitativos(elementos_dict, num_muestras=1000):\n",
    "    \"\"\"\n",
    "    elementos_dict: {'H': perfil_picos_H, 'He': perfil_picos_He, ...}\n",
    "    \"\"\"\n",
    "    X = [] # Espectros (Imágenes o vectores 1D)\n",
    "    y = [] # Concentraciones (Las \"respuestas\" para la IA)\n",
    "\n",
    "    for _ in range(num_muestras):\n",
    "        # 1. Generar concentraciones aleatorias que sumen 1 (100%)\n",
    "        # Esto es lo que la IA debe aprender a predecir\n",
    "        concentraciones = np.random.dirichlet(np.ones(len(elementos_dict)), size=1)[0]\n",
    "        \n",
    "        # 2. Crear el espectro combinado\n",
    "        espectro_total = np.zeros(longitud_onda_rango)\n",
    "        \n",
    "        for i, (nombre, perfil) in enumerate(elementos_dict.items()):\n",
    "            # Multiplicamos el perfil físico por su concentración\n",
    "            espectro_total += concentraciones[i] * perfil\n",
    "            \n",
    "        # 3. Añadir \"Ruido de Laboratorio\" (para que no sea perfecto)\n",
    "        ruido = np.random.normal(0, 0.02, longitud_onda_rango)\n",
    "        espectro_total += ruido\n",
    "        \n",
    "        X.append(espectro_total)\n",
    "        y.append(concentraciones)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 1. Definimos el rango de longitud de onda (igual que en tu app)\n",
    "longitud_onda_rango = 800 - 350  # 450 puntos si vas de 1 en 1 nm\n",
    "x_wavelengths = np.linspace(350, 800, longitud_onda_rango)\n",
    "\n",
    "# 2. Creamos los perfiles físicos (Firma de cada elemento)\n",
    "# Aquí simulamos dónde están los picos principales\n",
    "def crear_perfil(picos):\n",
    "    perfil = np.zeros(longitud_onda_rango)\n",
    "    for p in picos:\n",
    "        # Usamos una gaussiana para dar forma al pico\n",
    "        perfil += np.exp(-0.5 * ((x_wavelengths - p) / 2)**2)\n",
    "    return perfil\n",
    "\n",
    "# Firmas espectrales (esto es lo que pedirías a los expertos)\n",
    "perfiles_dict = {\n",
    "    \"Hidrogeno\": crear_perfil([434, 486, 656]),\n",
    "    \"Helio\": crear_perfil([447, 501, 587, 667]),\n",
    "    \"Sodio\": crear_perfil([589]),\n",
    "    \"Calcio\": crear_perfil([393, 396, 422, 445])\n",
    "}\n",
    "\n",
    "# 3. LLAMADA A LA FUNCIÓN (Aquí es donde se genera el dataset)\n",
    "print(\"Generando datos sintéticos para entrenamiento...\")\n",
    "X_train, y_train = generar_datos_cuantitativos(perfiles_dict, num_muestras=5000)\n",
    "\n",
    "print(f\"¡Listo! Dataset creado con {X_train.shape[0]} muestras.\")\n",
    "print(f\"Forma de los datos (X): {X_train.shape} -> (Muestras, Puntos de onda)\")\n",
    "print(f\"Forma de las etiquetas (y): {y_train.shape} -> (Muestras, Concentraciones)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7479fe7f",
   "metadata": {},
   "source": [
    "1. Arquitectura de la Red (1D-CNN)\n",
    "\n",
    "Esta estructura asume que tu espectro ha sido normalizado a un vector de tamaño fijo (por ejemplo, 1000 puntos de intensidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c52284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def crear_modelo_espectrometria(input_shape, num_elementos):\n",
    "    model = models.Sequential([\n",
    "        # --- EXTRACCIÓN DE CARACTERÍSTICAS ---\n",
    "        # Primera capa conv: Detecta formas básicas de picos\n",
    "        layers.Conv1D(filters=32, kernel_size=7, activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        \n",
    "        # Segunda capa conv: Detecta combinaciones de picos (patrones de elementos)\n",
    "        layers.Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        \n",
    "        # Tercera capa conv: Patrones más complejos\n",
    "        layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        layers.GlobalAveragePooling1D(), # Reduce el vector a sus características principales\n",
    "        \n",
    "        # --- CLASIFICACIÓN ---\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3), # Para evitar el sobreajuste (overfitting)\n",
    "        \n",
    "        # Capa de salida: Sigmoide para Clasificación Multi-etiqueta\n",
    "        # (Permite detectar varios elementos al mismo tiempo)\n",
    "        layers.Dense(num_elementos, activation='sigmoid') \n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy', # Ideal para multi-etiqueta\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# Si tu espectro tiene 1000 puntos y quieres detectar 10 elementos posibles:\n",
    "# input_shape = (1000, 1) -> (longitud, canales)\n",
    "modelo = crear_modelo_espectrometria((1000, 1), 10)\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26412e07",
   "metadata": {},
   "source": [
    "2. ¿Por qué esta arquitectura?\n",
    "\n",
    "    Conv1D (filtros): Imagina que el filtro es una pequeña ventana que se desliza sobre el espectro buscando la \"forma\" de un pico de Hidrógeno. Al tener varias capas, la red aprende primero a ver picos individuales y luego a reconocer \"familias\" de picos que definen a un elemento (como la serie de Balmer).\n",
    "\n",
    "    GlobalAveragePooling1D: En lugar de \"aplanar\" todo (Flatten), esta capa promedia los mapas de características. Esto hace que el modelo sea más ligero y menos propenso a memorizar el ruido.\n",
    "\n",
    "    Salida Sigmoide: En un problema de clasificación normal usamos Softmax (que elige solo uno), pero aquí usamos Sigmoid porque una sustancia puede ser una mezcla de Hierro, Carbono y Helio simultáneamente. Cada nodo de salida dará una probabilidad independiente (0 a 1) para cada elemento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a7321",
   "metadata": {},
   "source": [
    "Como los picos en espectrometría no son líneas infinitesimales sino que tienen un ancho debido al principio de incertidumbre y efectos térmicos (Doppler broadening), los modelamos comúnmente con la Función Gaussiana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41f297e",
   "metadata": {},
   "source": [
    "Aquí tienes cómo construir un generador de datos sintéticos robusto:\n",
    "1. Modelado Matemático de un Pico\n",
    "\n",
    "Un pico en la longitud de onda λ0​ se define como:\n",
    "I(λ)=A⋅exp(−2σ2(λ−λ0​)2​)\n",
    "\n",
    "Donde A es la intensidad (amplitud) y σ controla el ancho del pico.\n",
    "2. Generador de Espectros en Python\n",
    "\n",
    "Este script genera un espectro que combina:\n",
    "\n",
    "    Fondo de Cuerpo Negro (Usando una aproximación de la Ley de Planck).\n",
    "\n",
    "    Picos de Emisión (Gaussianas).\n",
    "\n",
    "    Ruido Blanco (Para que el ML aprenda a ignorarlo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0de2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generar_espectro_sintetico(longitudes_onda, elementos_presentes, ruido=0.02):\n",
    "    \"\"\"\n",
    "    longitudes_onda: array de numpy (ej. de 400 a 700 nm)\n",
    "    elementos_presentes: dict con {lambda_central: intensidad}\n",
    "    \"\"\"\n",
    "    # 1. Fondo de Cuerpo Negro (Simulado con una curva suave)\n",
    "    # En un caso real, usarías la fórmula de Planck con una T específica\n",
    "    continuo = 0.1 * np.exp(-(longitudes_onda - 550)**2 / (2 * 200**2))\n",
    "    \n",
    "    espectro = continuo.copy()\n",
    "    \n",
    "    # 2. Agregar picos de los elementos\n",
    "    for lam0, intensidad in elementos_presentes.items():\n",
    "        sigma = 1.5  # Ancho del pico\n",
    "        pico = intensidad * np.exp(-(longitudes_onda - lam0)**2 / (2 * sigma**2))\n",
    "        espectro += pico\n",
    "        \n",
    "    # 3. Agregar Ruido Aleatorio\n",
    "    espectro += np.random.normal(0, ruido, len(longitudes_onda))\n",
    "    \n",
    "    return np.clip(espectro, 0, 1) # Normalizar entre 0 y 1\n",
    "\n",
    "# --- EJEMPLO DE USO ---\n",
    "x = np.linspace(400, 800, 1000) # Rango visible en nm\n",
    "\n",
    "# Simulamos una sustancia con Hidrógeno (líneas H-alpha, beta, etc.)\n",
    "sustancia_x = {\n",
    "    656.3: 0.8, # H-alpha\n",
    "    486.1: 0.5, # H-beta\n",
    "    434.0: 0.3, # H-gamma\n",
    "    589.0: 0.6  # Un pico extra (ej. Sodio)\n",
    "}\n",
    "\n",
    "y = generar_espectro_sintetico(x, sustancia_x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Espectro Sintético Generado\")\n",
    "plt.xlabel(\"Longitud de onda (nm)\")\n",
    "plt.ylabel(\"Intensidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43f361",
   "metadata": {},
   "source": [
    "3. Estrategia para crear tu Dataset de Entrenamiento\n",
    "\n",
    "Para que tu modelo de Machine Learning sea realmente potente, debes automatizar la creación de miles de estos ejemplos:\n",
    "\n",
    "    Diccionario de Elementos: Crea un archivo JSON o una clase donde guardes las longitudes de onda características de cada elemento (H, He, Fe, etc.) según el NIST.\n",
    "\n",
    "    Combinaciones Aleatorias:\n",
    "\n",
    "        Crea una función que elija de 1 a 3 elementos al azar.\n",
    "\n",
    "        Asigne intensidades aleatorias a cada uno.\n",
    "\n",
    "        Genere el espectro y guarde el vector resultante (Input X) y un vector binario de etiquetas (Output Y).\n",
    "\n",
    "    Variabilidad: Varía ligeramente el parámetro σ (ancho de banda) y el nivel de ruido en cada ejemplo para que el modelo aprenda a ser flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1fec04",
   "metadata": {},
   "source": [
    "¿Cuál es el siguiente paso lógico?\n",
    "\n",
    "Podemos hacer una de estas dos cosas:\n",
    "\n",
    "    Crear el script de entrenamiento masivo: Generar 10,000 espectros y guardarlos en un formato que la red neuronal que diseñamos antes pueda leer.\n",
    "\n",
    "    Refinar el Simulador Streamlit: Hacer que el simulador permita al usuario \"mezclar\" elementos en tiempo real con sliders y ver cómo cambia el espectro antes de pasarlo por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a69843",
   "metadata": {},
   "source": [
    "Vamos a dividirlo en dos grandes fases. Empecemos con el Script de Entrenamiento Masivo.\n",
    "Fase 1: Script de Entrenamiento (Data Gen + Model Training)\n",
    "\n",
    "Este script hará tres cosas: generará miles de muestras, las etiquetará y entrenará la red neuronal que definimos antes.\n",
    "1. Definición de la \"Base de Datos\" Química\n",
    "\n",
    "Primero, definimos las líneas espectrales (longitudes de onda en nm) para los elementos que queremos que el modelo reconozca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921607d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import joblib # Para guardar etiquetas\n",
    "\n",
    "# Diccionario de elementos y sus líneas principales (simplificado)\n",
    "ELEMENT_DB = {\n",
    "    \"Hidrogeno\": [656.3, 486.1, 434.0, 410.2],\n",
    "    \"Helio\": [587.6, 667.8, 501.5, 447.1],\n",
    "    \"Sodio\": [589.0, 589.6],\n",
    "    \"Calcio\": [422.7, 393.4, 396.8]\n",
    "}\n",
    "\n",
    "ELEMENTOS = list(ELEMENT_DB.keys())\n",
    "NUM_ELEMENTOS = len(ELEMENTOS)\n",
    "X_RANGE = np.linspace(350, 800, 1000) # De UV cercano a IR cercano\n",
    "\n",
    "def generar_dataset(n_muestras=5000):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for _ in range(n_muestras):\n",
    "        espectro = np.zeros_like(X_RANGE)\n",
    "        etiquetas = np.zeros(NUM_ELEMENTOS)\n",
    "        \n",
    "        # Elegir de 1 a 3 elementos presentes al azar\n",
    "        n_presents = np.random.randint(1, 4)\n",
    "        indices_presents = np.random.choice(range(NUM_ELEMENTOS), n_presents, replace=False)\n",
    "        \n",
    "        for idx in indices_presents:\n",
    "            nombre = ELEMENTOS[idx]\n",
    "            etiquetas[idx] = 1 # One-hot encoding multietiqueta\n",
    "            intensidad_base = np.random.uniform(0.3, 1.0)\n",
    "            \n",
    "            # Agregar todas las líneas del elemento\n",
    "            for linea in ELEMENT_DB[nombre]:\n",
    "                # Pequeña variación en la posición por efecto Doppler/Ruido\n",
    "                pos = linea + np.random.normal(0, 0.2)\n",
    "                sigma = np.random.uniform(1.0, 2.0)\n",
    "                pico = intensidad_base * np.exp(-(X_RANGE - pos)**2 / (2 * sigma**2))\n",
    "                espectro += pico\n",
    "        \n",
    "        # Agregar ruido de fondo (Cuerpo Negro / Continuo)\n",
    "        espectro += 0.05 * np.random.random(len(X_RANGE)) \n",
    "        \n",
    "        # Normalizar espectro total\n",
    "        if espectro.max() > 0:\n",
    "            espectro /= espectro.max()\n",
    "            \n",
    "        X.append(espectro)\n",
    "        y.append(etiquetas)\n",
    "        \n",
    "    return np.array(X).reshape(-1, 1000, 1), np.array(y)\n",
    "\n",
    "# 2. Generar y Entrenar\n",
    "print(\"Generando datos...\")\n",
    "X_train, y_train = generar_dataset(8000)\n",
    "\n",
    "# Reutilizamos la arquitectura 1D-CNN que definimos antes\n",
    "# (Asegúrate de tener la función crear_modelo_espectrometria definida arriba)\n",
    "model = crear_modelo_espectrometria((1000, 1), NUM_ELEMENTOS)\n",
    "\n",
    "print(\"Entrenando modelo...\")\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 3. Exportar para Streamlit\n",
    "model.save('modelo_espectrometria.h5')\n",
    "joblib.dump(ELEMENTOS, 'etiquetas_elementos.pkl')\n",
    "print(\"¡Modelo guardado!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
